# **ðŸ“ Comando `uniq` en Linux**  

El comando `uniq` se usa en Linux para **eliminar lÃ­neas duplicadas consecutivas** en archivos de texto. Sin embargo, **solo funciona con lÃ­neas adyacentes repetidas**, por lo que es comÃºn combinarlo con `sort` para eliminar duplicados en toda la lista.  

ðŸ“Œ **CaracterÃ­sticas clave:**  
âœ… Filtra lÃ­neas duplicadas consecutivas.  
âœ… Puede contar cuÃ¡ntas veces aparece cada lÃ­nea.  
âœ… Funciona mejor cuando se combina con `sort`.  

---

### **ðŸ“Œ Uso BÃ¡sico de `uniq`**
### ðŸ”¹ Eliminar lÃ­neas duplicadas consecutivas  
```bash
uniq nombres.txt
```
ðŸ”¹ **ExplicaciÃ³n:**  
- Elimina **lÃ­neas repetidas consecutivas** en `nombres.txt`.  

### ðŸ”¹ Ordenar antes de eliminar duplicados  
```bash
sort nombres.txt | uniq
```
ðŸ”¹ **ExplicaciÃ³n:**  
- `sort` ordena el archivo, asegurando que las lÃ­neas duplicadas sean consecutivas.  
- `uniq` elimina las repeticiones.  

### ðŸ”¹ Contar repeticiones de cada lÃ­nea  
```bash
uniq -c nombres.txt
```
ðŸ”¹ **ExplicaciÃ³n:**  
- `-c` muestra cuÃ¡ntas veces aparece cada lÃ­nea.  
- Ãštil para **contar elementos Ãºnicos** en una lista.  

Ejemplo de salida:
```
  3 Juan
  2 Pedro
  5 MarÃ­a
```

---

## **ðŸ“ Comando `awk` en Linux**  

El comando `awk` es un lenguaje de programaciÃ³n orientado a **procesamiento de texto**. Es extremadamente potente para analizar archivos y extraer informaciÃ³n estructurada.  

ðŸ“Œ **CaracterÃ­sticas clave:**  
âœ… Extrae y manipula columnas de archivos de texto.  
âœ… Soporta **expresiones regulares** y lÃ³gica condicional.  
âœ… Ãštil para **generar reportes y analizar datos**.  

---

### **ðŸ“Œ Uso BÃ¡sico de `awk`**
### ðŸ”¹ Mostrar la primera columna de un archivo  
```bash
awk '{print $1}' archivo.txt
```
ðŸ”¹ **ExplicaciÃ³n:**  
- `$1` representa la **primera columna** de cada lÃ­nea.  

Ejemplo:  
Si `archivo.txt` contiene:
```
Juan 25
Pedro 30
MarÃ­a 27
```
El resultado serÃ¡:
```
Juan
Pedro
MarÃ­a
```

### ðŸ”¹ Mostrar las dos primeras columnas  
```bash
awk '{print $1, $2}' archivo.txt
```
ðŸ”¹ **ExplicaciÃ³n:**  
- `$1` = primera columna, `$2` = segunda columna.  

Salida:
```
Juan 25
Pedro 30
MarÃ­a 27
```

### ðŸ”¹ Filtrar lÃ­neas que contienen un valor especÃ­fico  
```bash
awk '$2 > 28 {print $1, $2}' archivo.txt
```
ðŸ”¹ **ExplicaciÃ³n:**  
- Filtra y muestra las lÃ­neas donde la segunda columna (`$2`) es mayor a `28`.  

Ejemplo de salida:
```
Pedro 30
```

### ðŸ”¹ Cambiar el delimitador de columnas  
Si un archivo usa `:` en lugar de espacios para separar columnas:  
```bash
awk -F ':' '{print $1, $3}' archivo.txt
```
ðŸ”¹ **ExplicaciÃ³n:**  
- `-F ':'` indica que el **delimitador** es `:`.  

---

## **ðŸŽ¯ ConclusiÃ³n**  
âœ… `uniq` se usa para **eliminar duplicados** en archivos de texto, pero funciona mejor con `sort`.  
âœ… `awk` es una **herramienta avanzada** para extraer y procesar informaciÃ³n en archivos estructurados.  
âœ… Ambos comandos son **fundamentales** para el anÃ¡lisis y manipulaciÃ³n de datos en Linux. ðŸš€

---

[Linux uniq Command: Duplicate Filtering](https://labex.io/tutorials/linux-linux-uniq-command-duplicate-filtering-219199)

[IBM.com: Awk by Example](https://developer.ibm.com/tutorials/l-awk1/)
[Linux Handbook: Awk](https://linuxhandbook.com/awk-command-tutorial/)
[Linux Awk Command: Text Processing](https://labex.io/tutorials/linux-linux-awk-command-text-processing-388493)
[Learning Awk is Essential for Linux Users](https://www.youtube.com/watch?v=9YOZmI-zWok)

[Explore top posts about Bash](https://app.daily.dev/tags/bash?ref=roadmapsh)
